/// <reference lib="DOM" />
import { LLMProvider, UnifiedChatRequest } from "../types/llm";
import { Transformer } from "../types/transformer";
import { log } from "../utils/log";
import { NewAPIToolCleaner } from "../utils/tool-cleaner";

// ç‰ˆæœ¬å·å¸¸é‡å®šä¹‰
const NEWAPI_VERSION = "v18.1"; // ğŸ¯ ç²¾ç®€ç¨³å®šç‰ˆæœ¬

// ğŸ”§ å®‰å…¨ä¸è°ƒè¯•é…ç½®
const SAFE_CONFIG = {
  // å®‰å…¨é˜ˆå€¼
  MAX_REASONING_LENGTH: 50000,    // æ¨ç†å†…å®¹æœ€å¤§é•¿åº¦
  MAX_CHUNKS_PER_REQUEST: 1000,   // æ¯è¯·æ±‚æœ€å¤§chunkæ•°
  
  // è°ƒè¯•æ¨¡å¼
  DEBUG_MODE: process.env.NEWAPI_DEBUG === 'true',
  LOG_RAW_DATA: process.env.NEWAPI_LOG_RAW === 'true'
};

// ğŸ” å¢å¼ºæ—¥å¿—ç³»ç»Ÿ - ç»“æ„åŒ–æ ‡è¯†ç¬¦ (ä¿æŒä¸å˜)
const LOG_PREFIX = `[NewAPI-${NEWAPI_VERSION}]`;
const LOG_MARKERS = {
  ENTRY: `${LOG_PREFIX} ğŸ“¥ [ENTRY]`,
  EXIT: `${LOG_PREFIX} ğŸ“¤ [EXIT]`,
  PROCESSING: `${LOG_PREFIX} âš™ï¸ [PROCESSING]`,
  MODEL_DETECT: `${LOG_PREFIX} ğŸ” [MODEL-DETECT]`,
  MODEL_THINKING: `${LOG_PREFIX} ğŸ§  [MODEL-THINKING]`,
  MSG_ANALYSIS: `${LOG_PREFIX} ğŸ“Š [MSG-ANALYSIS]`,
  MSG_TRANSFORM: `${LOG_PREFIX} ğŸ”„ [MSG-TRANSFORM]`,
  MSG_FIX: `${LOG_PREFIX} ğŸ”§ [MSG-FIX]`,
  MSG_VALIDATE: `${LOG_PREFIX} âœ… [MSG-VALIDATE]`,
  DEBUG_DETAIL: `${LOG_PREFIX} ğŸ” [DEBUG]`,
  DEBUG_CONTENT: `${LOG_PREFIX} ğŸ“ [DEBUG-CONTENT]`,
  DEBUG_STRUCTURE: `${LOG_PREFIX} ğŸ—ï¸ [DEBUG-STRUCTURE]`,
  SUCCESS: `${LOG_PREFIX} âœ… [SUCCESS]`,
  WARNING: `${LOG_PREFIX} âš ï¸ [WARNING]`,
  ERROR: `${LOG_PREFIX} âŒ [ERROR]`,
  INFO: `${LOG_PREFIX} â„¹ï¸ [INFO]`,
  TOOL_CLEAN: `${LOG_PREFIX} ğŸ§¹ [TOOL-CLEAN]`,
  TOOL_CHOICE: `${LOG_PREFIX} ğŸ¯ [TOOL-CHOICE]`,
  STATS: `${LOG_PREFIX} ğŸ“ˆ [STATS]`,
  SUMMARY: `${LOG_PREFIX} ğŸ“‹ [SUMMARY]`,
  RESPONSE_IN: `${LOG_PREFIX} ğŸ“¨ [RESPONSE-IN]`,
  RESPONSE_OUT: `${LOG_PREFIX} ğŸ“¤ [RESPONSE-OUT]`,
  STREAM_PROCESSING: `${LOG_PREFIX} ğŸŒŠ [STREAM]`,
  REASONING_CONVERT: `${LOG_PREFIX} ğŸ§  [REASONING-CONVERT]`,
  SAFETY_CHECK: `${LOG_PREFIX} ğŸ›¡ï¸ [SAFETY]`,
  DATA_FLOW: `${LOG_PREFIX} ğŸ“Š [DATA-FLOW]`,
  COMPLETION_DETECT: `${LOG_PREFIX} ğŸ¯ [COMPLETION-DETECT]`,
  SIGNATURE_GEN: `${LOG_PREFIX} ğŸ” [SIGNATURE]`,
  INDEX_HANDLE: `${LOG_PREFIX} ğŸ“ [INDEX]`,
  CONTENT_TRACK: `${LOG_PREFIX} ğŸ“ [CONTENT-TRACK]`,
  THINKING_TRACK: `${LOG_PREFIX} ğŸ§  [THINKING-TRACK]`,
  TEXT_TRACK: `${LOG_PREFIX} ğŸ“„ [TEXT-TRACK]`
};

/**
 * NewAPI Transformer - ç²¾ç®€ç¨³å®šç‰ˆ v18.1
 * 
 * ğŸ¯ æ ¸å¿ƒåŸåˆ™ï¼š
 * 1. ä¸“æ³¨æ ¸å¿ƒè½¬æ¢é€»è¾‘ï¼šå¤„ç†thinkingæ¨¡å¼çš„è¯·æ±‚å’Œå“åº”ã€‚
 * 2. ä¿ç•™è¯¦ç»†æ—¥å¿—ï¼šæä¾›å®Œæ•´çš„å¯è§‚æµ‹æ€§ã€‚
 * 3. ç§»é™¤å¤æ‚è®¾è®¡ï¼šå»é™¤A/Bæµ‹è¯•å¼€å…³å’Œå†—ä½™çš„è¾…åŠ©æ–¹æ³•ï¼Œä½¿ä»£ç æ›´æ˜“ç»´æŠ¤ã€‚
 */
export class NewAPITransformer implements Transformer {
  name = "newapi";
  version = `${NEWAPI_VERSION} - ç²¾ç®€ç¨³å®šç‰ˆ`;
  /**
   * å¤„ç†å‘é€ç»™NewAPIçš„è¯·æ±‚
   */
  transformRequestIn(
    request: UnifiedChatRequest,
    provider: LLMProvider
  ): Record<string, any> {
    log(`${LOG_MARKERS.ENTRY} å¼€å§‹å¤„ç†è¯·æ±‚ - æ¨¡å‹: ${request.model}`);
    
    if (request.messages) {
      log(`${LOG_MARKERS.MSG_ANALYSIS} åˆ†ææ¶ˆæ¯ç»“æ„ - æ¶ˆæ¯æ•°é‡: ${request.messages.length}`);
    }
    let transformedRequest = { ...request };

    log(`${LOG_MARKERS.PROCESSING} å¼€å§‹æ¨¡å‹æ£€æµ‹å’Œå‚æ•°ä¿®å¤`);
    if (this.isThinkingModel(transformedRequest.model)) {
      transformedRequest = this.fixThinkingModeParameters(transformedRequest);
    }

    if (transformedRequest.tools && transformedRequest.tools.length > 0) {
      log(`${LOG_MARKERS.TOOL_CLEAN} å¼€å§‹æ¸…ç†å·¥å…·å®šä¹‰ - å·¥å…·æ•°é‡: ${transformedRequest.tools.length}`);
      transformedRequest.tools = NewAPIToolCleaner.cleanTools(transformedRequest.tools);
      log(`${LOG_MARKERS.TOOL_CLEAN} å·¥å…·æ¸…ç†å®Œæˆ`);
    }

    const hasThinking = (transformedRequest as any).thinking ? 'Yes' : 'No';
    const toolCount = transformedRequest.tools ? transformedRequest.tools.length : 0;
    log(`${LOG_MARKERS.SUMMARY} è½¬æ¢å®Œæˆ - thinkingæ¨¡å¼: ${hasThinking}, å·¥å…·æ•°é‡: ${toolCount}`);
    log(`${LOG_MARKERS.EXIT} è¯·æ±‚å¤„ç†å®Œæˆ`);

    return transformedRequest;
  }

  /**
   * å¤„ç†ä»NewAPIè¿”å›çš„å“åº”ï¼ˆç²¾ç®€ç‰ˆï¼‰
   */
  async transformResponseOut(response: Response): Promise<Response> {
    log(`${LOG_MARKERS.RESPONSE_IN} å¼€å§‹å¤„ç†å“åº”è½¬æ¢`);
    if (response.headers.get("Content-Type")?.includes("text/event-stream")) {
      log(`${LOG_MARKERS.STREAM_PROCESSING} å¤„ç†æµå¼å“åº”`);
      
      if (!response.body) {
        log(`${LOG_MARKERS.WARNING} å“åº”ä½“ä¸ºç©ºï¼Œç›´æ¥è¿”å›`);
        return response;
      }

      const decoder = new TextDecoder();
      const encoder = new TextEncoder();

      const stream = new ReadableStream({
        async start(controller) {
          // æ¯ä¸ªæµç‹¬ç«‹çš„çŠ¶æ€å˜é‡ï¼Œé¿å…å¹¶å‘é—®é¢˜
          let chunkCounter = 0;
          let reasoningAccumulator = "";
          let isReasoningCompleted = false;
          let hasTextContent = false;

          const reader = response.body!.getReader();
          
          try {
            while (true) {
              const { done, value } = await reader.read();
              if (done) {
                log(`${LOG_MARKERS.DATA_FLOW} æµå¼å“åº”å®Œæˆ - æ€»chunks: ${chunkCounter}, reasoning: ${reasoningAccumulator.length > 0 ? 'Yes' : 'No'}, text: ${hasTextContent ? 'Yes' : 'No'}`);
                break;
              }

              const chunk = decoder.decode(value, { stream: true });
              const lines = chunk.split("\n");

              for (const line of lines) {
                if (line.startsWith("data: ") && line.trim() !== "data: [DONE]") {
                  try {
                    let data = JSON.parse(line.slice(6));
                    chunkCounter++;

                    // ğŸ›¡ï¸ å®‰å…¨æ£€æŸ¥
                    if (chunkCounter > SAFE_CONFIG.MAX_CHUNKS_PER_REQUEST) {
                      log(`${LOG_MARKERS.WARNING} chunkæ•°é‡è¶…é™ï¼Œè·³è¿‡`);
                      continue;
                    }

                    const delta = data.choices?.[0]?.delta;
                    if (delta) {
                      // è¿½è¸ªæ¨ç†å†…å®¹
                      if (delta.reasoning_content) {
                        reasoningAccumulator += delta.reasoning_content;
                        log(`${LOG_MARKERS.THINKING_TRACK} æ¨ç†å†…å®¹ç´¯ç§¯ - å½“å‰é•¿åº¦: ${reasoningAccumulator.length}, æ–°å¢: ${delta.reasoning_content.length}`);
                      }

                      // è¿½è¸ªæ­£æ–‡å†…å®¹
                      if (delta.content && !hasTextContent) {
                        hasTextContent = true;
                      }

                      // ğŸ”§ å…³é”®è½¬æ¢ï¼šå°†reasoning_contentè½¬æ¢ä¸ºthinking
    if (delta.reasoning_content) {
                        log(`${LOG_MARKERS.REASONING_CONVERT} è½¬æ¢reasoning_content â†’ delta.thinking`);
                        delta.thinking = { content: delta.reasoning_content };
                        delete delta.reasoning_content;
    }
                    }

                    // æ„å»ºå›å¤è¡Œ
                    const finalLine = `data: ${JSON.stringify(data)}\n\n`;
                    controller.enqueue(encoder.encode(finalLine));
    } catch (e: any) {
                    log(`${LOG_MARKERS.ERROR} JSONè§£æå¤±è´¥: ${e.message}`);
                    // å®‰å…¨å›é€€ï¼šé€ä¼ åŸå§‹è¡Œ
                    controller.enqueue(encoder.encode(line + "\n"));
    }
                } else {
                  // é€ä¼ éæ•°æ®è¡Œ
                  controller.enqueue(encoder.encode(line + "\n"));
                }
              }
            }
          } catch (error: any) {
            log(`${LOG_MARKERS.ERROR} æµå¼å“åº”å¤„ç†é”™è¯¯: ${error.message}`);
    try {
              controller.error(error);
            } catch (e) {
              controller.close();
    }
          } finally {
    try {
              reader.releaseLock();
              controller.close();
    } catch (e: any) {
              log(`${LOG_MARKERS.WARNING} æ¸…ç†æ—¶å‡ºé”™: ${e.message}`);
    }
  }
        },
      });

      return new Response(stream, {
        status: response.status,
        statusText: response.statusText,
        headers: response.headers,
      });
    } else {
      log(`${LOG_MARKERS.RESPONSE_IN} å¤„ç†éæµå¼å“åº”`);
      const jsonResponse = await response.json();

      if (jsonResponse.choices?.[0]?.message?.reasoning_content) {
        log(`${LOG_MARKERS.REASONING_CONVERT} æ£€æµ‹åˆ°reasoning_contentï¼Œè½¬æ¢ä¸ºthinkingæ ¼å¼`);
        const reasoning = jsonResponse.choices[0].message.reasoning_content;
        jsonResponse.choices[0].message.thinking = { content: reasoning };
      }

      return new Response(JSON.stringify(jsonResponse), {
        status: response.status,
        statusText: response.statusText,
        headers: response.headers,
      });
    }
  }

  /**
   * ä¿®å¤Claude thinkingæ¨¡å¼çš„å‚æ•°æ ¼å¼
   */
  private fixThinkingModeParameters(request: UnifiedChatRequest): UnifiedChatRequest {
    log(`${LOG_MARKERS.MODEL_THINKING} å¼€å§‹ä¿®å¤thinkingæ¨¡å¼å‚æ•°`);
    const fixedRequest = { ...request };

    (fixedRequest as any).thinking = {
      type: "enabled",
      budget_tokens: 10000
    };
    log(`${LOG_MARKERS.MODEL_THINKING} å·²æ·»åŠ thinkingå‚æ•°: type=enabled, budget_tokens=10000`);

    if (fixedRequest.messages && fixedRequest.messages.length > 0) {
      fixedRequest.messages = this.fixMessagesForThinking(fixedRequest.messages);
  }

    if (fixedRequest.tool_choice && typeof fixedRequest.tool_choice === 'object') {
      if (fixedRequest.tool_choice.type === "any" || fixedRequest.tool_choice.type === "tool") {
        log(`${LOG_MARKERS.TOOL_CHOICE} ä¿®æ­£tool_choice: ä¸æ”¯æŒthinkingæ¨¡å¼çš„'${fixedRequest.tool_choice.type}'ï¼Œæ”¹ä¸º'auto'`);
        fixedRequest.tool_choice = "auto";
} 
    }

    log(`${LOG_MARKERS.MODEL_THINKING} thinkingæ¨¡å¼å‚æ•°ä¿®å¤å®Œæˆ`);
    return fixedRequest;
  }

  private fixMessagesForThinking(messages: any[]): any[] {
    log(`${LOG_MARKERS.MSG_ANALYSIS} å¼€å§‹åˆ†ææ¶ˆæ¯æ ¼å¼ - æ€»æ¶ˆæ¯æ•°: ${messages.length}`);
    const messageStats: { [key: string]: number } = {};
    messages.forEach((msg, i) => {
      messageStats[msg.role] = (messageStats[msg.role] || 0) + 1;
    });

    log(`${LOG_MARKERS.STATS} æ¶ˆæ¯ç»Ÿè®¡: ${Object.entries(messageStats).map(([role, count]) => `${role}=${count}`).join(', ')}`);

    const assistantIndices: number[] = [];
    for (let i = 0; i < messages.length; i++) {
      if (messages[i].role === 'assistant') {
        assistantIndices.push(i);
      }
    }

    if (assistantIndices.length === 0) {
      log(`${LOG_MARKERS.INFO} æœªæ‰¾åˆ°assistantæ¶ˆæ¯ï¼Œæ— éœ€ä¿®å¤thinkingå—`);
      return messages;
    }

    log(`${LOG_MARKERS.MSG_FIX} æ‰¾åˆ°${assistantIndices.length}ä¸ªassistantæ¶ˆæ¯ï¼Œå¤„ç†ä¸­`);
    let fixedCount = 0;

    for (const index of assistantIndices) {
      const original = messages[index];
      const fixed = this.ensureThinkingBlock(original.content, index);

      if (fixed !== original.content) {
        messages[index] = { ...original, content: fixed };
        fixedCount++;
      }
    }

    log(`${LOG_MARKERS.SUMMARY} thinkingå—ä¿®å¤å®Œæˆ: ä¿®å¤äº†${fixedCount}ä¸ªassistantæ¶ˆæ¯`);
    return messages;
  }

  private ensureThinkingBlock(content: any, messageIndex: number): any {
    if (!content || (Array.isArray(content) && content.length === 0)) {
      log(`${LOG_MARKERS.WARNING} assistantæ¶ˆæ¯[${messageIndex}] contentä¸ºç©ºï¼Œä»…æ·»åŠ thinkingå—`);
      return [
        { type: 'thinking', text: 'æˆ‘æ­£åœ¨å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚' }
      ];
    }

    if (typeof content === 'string') {
      log(`${LOG_MARKERS.MSG_TRANSFORM} assistantæ¶ˆæ¯[${messageIndex}] å­—ç¬¦ä¸²contentè½¬æ¢ä¸ºæ•°ç»„å¹¶æ·»åŠ thinkingå—`);
      return [
        { type: 'thinking', text: 'è®©æˆ‘åˆ†æè¿™ä¸ªè¯·æ±‚ã€‚' },
        { type: 'text', text: content }
      ];
    }

    if (Array.isArray(content)) {
      const hasThinking = content.length > 0 && ["thinking", "redacted_thinking"].includes(content[0]?.type);
      if (hasThinking) return content;

      log(`${LOG_MARKERS.MSG_FIX} assistantæ¶ˆæ¯[${messageIndex}] ç¼ºå°‘thinkingå—ï¼Œæ·»åŠ åˆ°å¼€å¤´`);
      const hasToolUse = content.some((block: any) => block.type === "tool_use");
      const thinkingText = hasToolUse ? "æˆ‘éœ€è¦ä½¿ç”¨å·¥å…·æ¥å®Œæˆè¿™ä¸ªè¯·æ±‚ã€‚" : "æˆ‘æ­£åœ¨åˆ†æè¿™ä¸ªè¯·æ±‚å¹¶å‡†å¤‡å›åº”ã€‚";
      return [
        { type: 'thinking', text: thinkingText },
        ...content
      ];
    }

    return content;
  }

  /**
   * æ£€æµ‹æ˜¯å¦ä¸ºthinkingæ¨¡å¼æ¨¡å‹
   */
  private isThinkingModel(model: string): boolean {
    // æ£€æµ‹æ¨¡å‹åä¸­æ˜¯å¦åŒ…å«"thinking"
    const hasThinkingInName = model.includes("thinking");

    // æ£€æµ‹æ˜¯å¦ä¸ºæ”¯æŒthinkingçš„ç‰¹å®šClaudeæ¨¡å‹
    const isClaude4ThinkingModel =
      model.includes("claude-sonnet-4-20250514") ||
      model.includes("claude-opus-4-20250514") ||
      model.includes("claude-3-7-sonnet");

    // ğŸ†• æ–°å¢ï¼šæ£€æµ‹æ˜¯å¦ä¸ºéœ€è¦å¯ç”¨thinkingæ¨¡å¼çš„Geminiæ¨¡å‹
    const isGeminiProThinkingModel = model.includes("gemini-2.5-pro");

    const isThinking = hasThinkingInName || isClaude4ThinkingModel || isGeminiProThinkingModel;

    log(`${LOG_MARKERS.MODEL_DETECT} æ¨¡å‹æ£€æµ‹: "${model}"`);
    log(`${LOG_MARKERS.MODEL_DETECT}   - åç§°åŒ…å«thinking: ${hasThinkingInName}`);
    log(`${LOG_MARKERS.MODEL_DETECT}   - æ˜¯Claude4æ¨¡å‹: ${isClaude4ThinkingModel}`);
    log(`${LOG_MARKERS.MODEL_DETECT}   - æ˜¯Gemini 2.5 Proæ¨¡å‹: ${isGeminiProThinkingModel}`); // ğŸ†• æ–°å¢æ—¥å¿—
    log(`${LOG_MARKERS.MODEL_DETECT}   - æœ€ç»ˆåˆ¤æ–­: ${isThinking ? 'å¯ç”¨thinkingæ¨¡å¼' : 'ä¸å¯ç”¨thinkingæ¨¡å¼'}`);

    return isThinking;
  }
  transformRequestOut(request: Record<string, any>): UnifiedChatRequest {
    return request as UnifiedChatRequest;
  }
}
